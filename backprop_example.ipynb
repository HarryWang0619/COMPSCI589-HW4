{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "from stratified import *\n",
    "from neuralnetwork import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta 1\n",
    "# 0.40000  0.10000  \n",
    "# 0.30000  0.20000  \n",
    "theta1 = np.array([[0.4, 0.1],[0.3,0.2]])\n",
    "# Theta 2 \n",
    "#   0.70000  0.50000  0.60000\n",
    "theta2 = np.array([0.7,0.5,0.6])\n",
    "weightlist1= [theta1,theta2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "# \tTraining instance 1\n",
    "# \t\tx: [0.13000]\n",
    "# \t\ty: [0.90000]\n",
    "# \tTraining instance 2\n",
    "# \t\tx: [0.42000]\n",
    "# \t\ty: [0.23000]\n",
    "# Training instance 1\n",
    "trainingcategory = {'x1':'numerical', 'y':'class_numerical'}\n",
    "trainingdata1 = np.array([0.13,0.9])\n",
    "trainingdata2 = np.array([0.42,0.23])\n",
    "inputdata1 = np.append(1,trainingdata1[0])\n",
    "inputdata2 = np.append(1,trainingdata2[0])\n",
    "exceptout1 = trainingdata1[1]\n",
    "exceptout2 = trainingdata2[1]\n",
    "lambda1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardtest(inputdata,weightl,expectedout):\n",
    "    current_layer_a = inputdata\n",
    "    print('current_a at 1 is',current_layer_a)\n",
    "    current_layer_index = 0\n",
    "    alist = []\n",
    "    alist.append(current_layer_a)\n",
    "    for theta in weightl:\n",
    "        z = np.dot(theta,current_layer_a)\n",
    "        a = g(z)\n",
    "        current_layer_a = np.append(1,a) if (current_layer_index+1 != len(weightl)) else a\n",
    "        print('current_a at',current_layer_index+2,'is',current_layer_a)\n",
    "        alist.append(current_layer_a)\n",
    "        current_layer_index += 1\n",
    "    result = current_layer_a\n",
    "    print('prediction is', result)\n",
    "    print('exceptout is', expectedout)\n",
    "    print('cost is', costfunction(expectedout,result))\n",
    "    return result, costfunction(expectedout,result), alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_a at 1 is [1.   0.13]\n",
      "current_a at 2 is [1.        0.601807  0.5807858]\n",
      "current_a at 3 is 0.7940274264318581\n",
      "prediction is 0.7940274264318581\n",
      "exceptout is 0.9\n",
      "cost is 0.36557477431084995\n"
     ]
    }
   ],
   "source": [
    "r1,j1,a1 = forwardtest(inputdata1,weightlist1,exceptout1)\n",
    "# Computing the error/cost, J, of the network\n",
    "# \tProcessing training instance 1\n",
    "# \tForward propagating the input [0.13000]\n",
    "# \t\ta1: [1.00000   0.13000]\n",
    "\n",
    "# \t\tz2: [0.41300   0.32600]\n",
    "# \t\ta2: [1.00000   0.60181   0.58079]\n",
    "\n",
    "# \t\tz3: [1.34937]\n",
    "# \t\ta3: [0.79403]\n",
    "\n",
    "# \t\tf(x): [0.79403]\n",
    "# \tPredicted output for instance 1: [0.79403]\n",
    "# \tExpected output for instance 1: [0.90000]\n",
    "# \tCost, J, associated with instance 1: 0.366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_a at 1 is [1.   0.42]\n",
      "current_a at 2 is [1.         0.60873549 0.59483749]\n",
      "current_a at 3 is 0.7959660671522611\n",
      "prediction is 0.7959660671522611\n",
      "exceptout is 0.23\n",
      "cost is 1.2763768066887786\n"
     ]
    }
   ],
   "source": [
    "r2,j2,a2 = forwardtest(inputdata2,weightlist1,exceptout2)\n",
    "\t# Processing training instance 2\n",
    "\t# Forward propagating the input [0.42000]\n",
    "\t# \ta1: [1.00000   0.42000]\n",
    "\n",
    "\t# \tz2: [0.44200   0.38400]\n",
    "\t# \ta2: [1.00000   0.60874   0.59484]\n",
    "\n",
    "\t# \tz3: [1.36127]\n",
    "\t# \ta3: [0.79597]\n",
    "\n",
    "\t# \tf(x): [0.79597]\n",
    "\t# Predicted output for instance 2: [0.79597]\n",
    "\t# Expected output for instance 2: [0.23000]\n",
    "\t# Cost, J, associated with instance 2: 1.276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "jlist1 = np.array([j1,j2])\n",
    "numberofinstance1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overallcost(jlist,n,weightl):\n",
    "    s = sumofweights(weightl,bias=1)*lambda1/(2*n)\n",
    "    jsum = np.sum(jlist)\n",
    "    return jsum/n + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8209757904998143"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overallcost(jlist1,numberofinstance1,weightlist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "\t# Computing gradients based on training instance 1\n",
    "\t# \tdelta3: [-0.10597]\n",
    "\t# \tdelta2: [-0.01270   -0.01548]\n",
    "\t\t\n",
    "\t# \tGradients of Theta2 based on training instance 1:\n",
    "\t# \t\t-0.10597  -0.06378  -0.06155  \n",
    "\n",
    "\t# \tGradients of Theta1 based on training instance 1:\n",
    "\t# \t\t-0.01270  -0.00165  \n",
    "\t# \t\t-0.01548  -0.00201  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blame(predict_output, expected_output, weights_list, a_list, biasterm=True): # This is to find out the delta function\n",
    "    deltalist = []\n",
    "    delta_layer_l = predict_output - expected_output\n",
    "    deltalist.append(delta_layer_l)\n",
    "    i = len(weights_list)-1\n",
    "    current_delta = delta_layer_l\n",
    "\n",
    "    while i > 0:\n",
    "        attributeblame = np.dot(a_list[i+1],(1-a_list[i+1]))\n",
    "        rawblame = np.dot(weights_list[i].T,current_delta)\n",
    "        delta_layer_now = np.dot(rawblame,attributeblame)\n",
    "        if biasterm:\n",
    "            delta_layer_now[0] = 1 # the first attribute is the bias\n",
    "            current_delta = delta_layer_now[1:] # the first attribute is the bias\n",
    "        else:\n",
    "            current_delta = delta_layer_now\n",
    "        deltalist.append(current_delta)\n",
    "        i-=1\n",
    "    deltalist.reverse()\n",
    "    \n",
    "    return deltalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta(weightl,alist,expect,actual):\n",
    "    delta_layer_n = actual-expect\n",
    "    deltalist = []\n",
    "    deltalist.append(delta_layer_n)\n",
    "    i = len(weightl)-1\n",
    "    current_layer_delta = delta_layer_n\n",
    "\n",
    "    while i > 0:\n",
    "        print(weightl[i])\n",
    "        print(alist[i])\n",
    "\n",
    "        ablame = np.multiply(alist[i],(1-alist[i]))\n",
    "        print('a',ablame)\n",
    "        step1 = np.multiply(np.multiply(np.dot(weightl[i].T,current_layer_delta),alist[i]),(1-alist[i]))\n",
    "        delta_layer_now = step1\n",
    "        current_delta = delta_layer_now[1:]\n",
    "        print('delta',current_delta)\n",
    "        deltalist.append(current_delta)\n",
    "        i-=1\n",
    "    deltalist.reverse()\n",
    "    return deltalist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.6]\n",
      "[1.        0.601807  0.5807858]\n",
      "a [0.         0.23963533 0.24347365]\n",
      "delta [-0.01269739 -0.01548092]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.01269739, -0.01548092]), -0.10597257356814194]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta(weightlist1,a1,exceptout1,r1)\n",
    "\t# \tdelta3: [-0.10597]\n",
    "\t# \tdelta2: [-0.01270   -0.01548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.  , 0.42]), array([1.        , 0.60873549, 0.59483749]), 0.7959660671522611]\n"
     ]
    }
   ],
   "source": [
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation Example 2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
